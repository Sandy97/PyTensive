# Курсовой проект по теме

## Машинное обучение 6: обучение с подкреплением

#### Задание

Выберите одно из окружение AI Gym - Classic Control (кроме CartPole) или Box2D - https://gym.openai.com/envs/  

Изучите действия агента в заданной среде. Постройте алгоритм машинного обучения с подкреплением, который решает поставленную задачу после нужного количества обучающих эпизодов.  

Выложите полный код решения в вашем репозитории GitHub. Приложите ссылку на решение в репозитории в ответе к заданию.

#### Содержимое

Для проекта была выбрана среда  [Mountain Car - Gym Documentation](https://www.gymlibrary.dev/environments/classic_control/mountain_car/) из раздела [Classic Control environments](https://www.gymlibrary.dev/environments/classic_control/)

<img src="https://www.gymlibrary.dev/_images/mountain_car.gif" title="" alt="../../../_images/mountain_car.gif" width="238">

![](C:\Users\Sovtsov\AppData\Roaming\marktext\images\2023-06-23-22-00-09-image.png)

#### Способы решения:

1. Улучшенный Q-learning на примере

2. Улучшенный DNQ

3. A2C

| Path                                               |                                                                                                                                                                                                                                                                                                                             |
|:-------------------------------------------------- |:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| "Practicum\ML6 с подкреплением\MountainCar-v0_DQN" | Каталог с DQN решением <br/>в каталоге находятся следующие файлы:                                                                                                                                                                                                                                                           |
|                                                    | ![](C:\Users\Sovtsov\AppData\Roaming\marktext\images\2023-06-23-22-39-00-image.png)                                                                                                                                                                                                                                         |
|                                                    | - протокол обучения<br/>- Исходный текст решения на Python<br/>- окончательный график обучения<br/><br/>Главной проблемой обучения стала нехватка машинных ресурсов, поэтому для решения была создана небольшая сеть 32-16-3, а обучение проводилось на 200 эпизодах.  Однако, этого стало вполне достаточно для результата |
| MountainCar-v0_Qlearning(Kaggle).ipynb             | Пример решения с алгоритмом улучшенного Q-learning                                                                                                                                                                                                                                                                          |
|                                                    | Обучение выполнялось на 10000 и 5000 эпизодов                                                                                                                                                                                                                                                                               |
| MountainCar-v0_A2C_2.5e-05.ipynb                   | Блокнот с решением с использованием дуэльных сетей A2C<br/>Главной проблемой обучения также стала нехватка машинных ресурсов, поэтому для решения была создана простая Dense сеть, а обучение пришлось прервать после 500 эпизодов. Обучение медленное. Недообучение?                                                       |
|                                                    | \|                                                                                                                                                                                                                                                                                                                          |
|                                                    |                                                                                                                                                                                                                                                                                                                             |
