{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузите данные, приведите их к числовым, заполните пропуски, нормализуйте данные и оптимизируйте память.\n",
    "\n",
    "Разделите выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Постройте **2 модели** - **kNN по 100** соседей и **множественную логистическую регрессию** - по __наиболее оптимальным наборам параметров (для каждой модели)__, используйте для этого **перекрестную проверку GridSearchCV**.\n",
    "\n",
    "Проведите предсказание и проверьте качество через каппа-метрику.\n",
    "\n",
    "Какая модель дала наибольшую точность: логистическая регрессия или kNN ?\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 133 entries, Id to Product_Info_2_1_E\n",
      "dtypes: float64(18), int64(110), uint8(5)\n",
      "memory usage: 58.3 MB\n",
      "None\n",
      "   Id  Product_Info_1  Product_Info_3  Product_Info_4  Product_Info_5  \\\n",
      "0   2               1              10        0.076923               2   \n",
      "1   5               1              26        0.076923               2   \n",
      "2   6               1              26        0.076923               2   \n",
      "3   7               1              10        0.487179               2   \n",
      "4   8               1              26        0.230769               2   \n",
      "\n",
      "   Product_Info_6  Product_Info_7   Ins_Age        Ht        Wt  ...  \\\n",
      "0               1               1  0.641791  0.581818  0.148536  ...   \n",
      "1               3               1  0.059701  0.600000  0.131799  ...   \n",
      "2               3               1  0.029851  0.745455  0.288703  ...   \n",
      "3               3               1  0.164179  0.672727  0.205021  ...   \n",
      "4               3               1  0.417910  0.654545  0.234310  ...   \n",
      "\n",
      "   Medical_Keyword_46  Medical_Keyword_47  Medical_Keyword_48  Response  \\\n",
      "0                   0                   0                   0         8   \n",
      "1                   0                   0                   0         4   \n",
      "2                   0                   0                   0         8   \n",
      "3                   0                   0                   0         8   \n",
      "4                   0                   0                   0         8   \n",
      "\n",
      "   Product_Info_2_2  Product_Info_2_1_A  Product_Info_2_1_B  \\\n",
      "0                 3                   0                   0   \n",
      "1                 1                   1                   0   \n",
      "2                 1                   0                   0   \n",
      "3                 4                   0                   0   \n",
      "4                 2                   0                   0   \n",
      "\n",
      "   Product_Info_2_1_C  Product_Info_2_1_D  Product_Info_2_1_E  \n",
      "0                   0                   1                   0  \n",
      "1                   0                   0                   0  \n",
      "2                   0                   0                   1  \n",
      "3                   0                   1                   0  \n",
      "4                   0                   1                   0  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.get_dummies(data=data,prefix='Product_Info_2_1')\n",
    "# df1[\"Product_Info_2_1\"].head()\n",
    "# df1.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1_A', 'Product_Info_2_1_B', 'Product_Info_2_1_C', 'Product_Info_2_1_D', 'Product_Info_2_1_E']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (минус 75.1 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 119 entries, 0 to Response\n",
      "dtypes: float16(118), int8(1)\n",
      "memory usage: 13.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "print (data_transformed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "33085  1.483398 -1.934570  1.576172  3.925781  0.611816 -0.169434 -1.159180   \n",
      "14814  0.308838  1.003906  0.441162 -0.213135 -1.634766 -0.169434  0.862305   \n",
      "1144  -1.218750 -0.220581  1.424805 -1.389648  0.611816 -0.169434 -1.159180   \n",
      "21288 -0.043610 -0.465576 -0.770020  0.290771  0.611816 -0.169434 -1.159180   \n",
      "36828  0.003372 -1.690430  0.895020  1.322266  0.611816 -0.169434 -1.159180   \n",
      "\n",
      "              7         8         9  ...       109      110       111  \\\n",
      "33085  1.100586 -1.156250  1.130859  ... -0.083679  0.44165 -0.149292   \n",
      "14814 -1.013672  0.862305  0.100891  ... -0.083679  0.44165 -0.149292   \n",
      "1144   1.100586 -1.156250  1.130859  ... -0.083679  0.44165 -0.149292   \n",
      "21288  1.100586 -1.156250  1.130859  ... -0.083679  0.44165 -0.149292   \n",
      "36828  1.100586 -1.156250  1.130859  ... -0.083679  0.44165 -0.149292   \n",
      "\n",
      "            112       113      114       115       116       117  Response  \n",
      "33085  1.666992  1.604492 -0.14209 -0.128906 -1.332031 -0.215942         2  \n",
      "14814 -1.133789 -0.623535 -0.14209 -0.128906 -1.332031  4.628906         8  \n",
      "1144  -1.133789 -0.623535 -0.14209 -0.128906 -1.332031  4.628906         2  \n",
      "21288 -0.200073 -0.623535 -0.14209 -0.128906  0.750977 -0.215942         7  \n",
      "36828 -0.200073 -0.623535 -0.14209 -0.128906  0.750977 -0.215942         5  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2,\n",
    "                                         random_state=10)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "Найдем оптимальный набор столбцов и рассчитаем по нему модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Функции взяты из варианта возможного решения\n",
    "\n",
    "# regression_model\n",
    "# Создает модель LogisticRegression с заданными параметрами \n",
    "#                и обучает ее, если указано при вызове\n",
    "\n",
    "def regression_model (columns, df, fit=True):\n",
    "    x = pd.DataFrame(df, columns=columns)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    if fit:\n",
    "        model.fit(x, y = df[\"Response\"])\n",
    "    return model\n",
    "\n",
    "# model_score\n",
    "# подбор гиперпараметров указанной модели по сетке\n",
    "# Оценка по метрике cohen_kappa_score\n",
    "\n",
    "def model_score (columns, df_train, model_func):\n",
    "    x = pd.DataFrame(df_train, columns=columns)\n",
    "    model = model_func(columns, df_train, False)   # модель должна быть уже обучена\n",
    "    cv_grid = GridSearchCV(estimator=model, \n",
    "                           param_grid={}, \n",
    "                           cv=5, \n",
    "                           n_jobs=2,\n",
    "                           scoring=make_scorer(cohen_kappa_score))\n",
    "    cv_grid.fit(x, df_train[\"Response\"])\n",
    "    return cv_grid.best_score_\n",
    "\n",
    "# find_opt_columns\n",
    "# Поиск оптимального набора параметров модели\n",
    "# возвращает оптимальный набор колонок и его метрику\n",
    "\n",
    "def find_opt_columns (data_train, model_func):\n",
    "    kappa_score_opt = 0\n",
    "    columns_opt = []\n",
    "    # для каждой колонки ищем с наилучшей метрикой\n",
    "    for col in columns_transformed:\n",
    "        kappa_score = model_score([col], data_train, model_func)\n",
    "        if kappa_score > kappa_score_opt:\n",
    "            columns_opt = [col]\n",
    "            kappa_score_opt = kappa_score\n",
    "    # для каждой из всех оставшихся проверяем: \n",
    "    #     не улучшается ли метрика, если ее добавить в параметры модели\n",
    "    # возвращаем набор с самой лучшей метрикой и значение его метрики\n",
    "    for col in columns_transformed:\n",
    "        if col not in columns_opt:\n",
    "            columns_opt.append(col)\n",
    "            kappa_score = model_score(columns_opt, data_train, model_func)\n",
    "            if kappa_score < kappa_score_opt:\n",
    "                columns_opt.pop()\n",
    "            else:\n",
    "                kappa_score_opt = kappa_score\n",
    "    return columns_opt, kappa_score_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_logr:\n",
      " 0.3479962343405738 [3, 0, 2, 4, 5, 6, 8, 9, 10, 11, 14, 16, 20, 21, 24, 26, 34, 40, 41, 42, 46, 48, 49, 50, 59, 61, 62, 63, 64, 65, 68, 69, 71, 73, 74, 76, 77, 78, 79, 80, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 98, 99, 102, 103, 104, 106, 107, 108, 112, 113, 115, 116, 117]\n"
     ]
    }
   ],
   "source": [
    "columns_opt_logr, kappa_score_opt = find_opt_columns(data_train,\n",
    "                                                    regression_model)\n",
    "model_logr = regression_model(columns_opt_logr, data_train)\n",
    "print ('model_logr:\\n', kappa_score_opt, columns_opt_logr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN\n",
    "Посчитаем оптимальную модель для kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model (columns, df_train, fit=True):\n",
    "    y = data_train[\"Response\"]\n",
    "    x = pd.DataFrame(df_train, columns=columns)\n",
    "    model = KNeighborsClassifier(n_neighbors=100)\n",
    "    if fit:\n",
    "        model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3657125849625779 [3, 2, 4, 5, 14, 26, 34, 46, 49, 68, 69, 75, 79, 91, 94, 96, 99, 104]\n"
     ]
    }
   ],
   "source": [
    "columns_opt_knn, kappa_score_opt = find_opt_columns(data_train,\n",
    "                                                    knn_model)\n",
    "model_knn = knn_model(columns_opt_knn, data_train)\n",
    "print (kappa_score_opt, columns_opt_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(data_test, columns=columns_opt_logr)\n",
    "data_test[\"target_logr\"] = model_logr.predict(x_test)\n",
    "x_test = pd.DataFrame(data_test, columns=columns_opt_knn)\n",
    "data_test[\"target_knn\"] = model_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: 0.475\n",
      "kNN, 100: 0.457\n"
     ]
    }
   ],
   "source": [
    "print (\"Логистическая регрессия:\",\n",
    "      round(cohen_kappa_score(data_test[\"target_logr\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))\n",
    "print (\"kNN, 100:\",\n",
    "      round(cohen_kappa_score(data_test[\"target_knn\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      " [[ 267  155   11   10   67  138   55   32]\n",
      " [ 186  264   11    4  136  162   44   14]\n",
      " [  10   14   20    4    2    4    0    0]\n",
      " [  13   10   24   86    4   54    7    9]\n",
      " [ 107  183   11    0  282  139   46   19]\n",
      " [ 216  267  117  137  297  945  246  231]\n",
      " [ 107   92    3    2   82  210  430   55]\n",
      " [ 305  288   12   34  240  627  790 3540]]\n",
      "kNN:\n",
      " [[ 186  115   12   10   44  102   33   16]\n",
      " [ 217  307    7    3  108  112   22   14]\n",
      " [   0    0    0    0    0    0    0    0]\n",
      " [   6    1    5   28    2   21    1    7]\n",
      " [  53  132   30    0  285  102    9   11]\n",
      " [ 282  302  141  200  332 1135  306  201]\n",
      " [ 146  130    6    5  119  278  599  109]\n",
      " [ 321  286    8   31  220  529  648 3542]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Логистическая регрессия:\\n\",\n",
    "      confusion_matrix(data_test[\"target_logr\"], data_test[\"Response\"]))\n",
    "print (\"kNN:\\n\",\n",
    "      confusion_matrix(data_test[\"target_knn\"], data_test[\"Response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
